{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto_id_garrafas_industria_am.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reis25/Bottles/blob/master/Projeto_id_garrafas_industria_am.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2jiDlsogSP8"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        " \n",
        " \n",
        "from PIL import Image\n",
        " \n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "plt.style.use('ggplot')\n",
        " \n",
        "    \n",
        "# load and display an image with Matplotlib\n",
        "#from matplotlib import image\n",
        " \n",
        "batch_size = 8\n",
        "num_classes = 8\n",
        "epochs = 100\n",
        " \n",
        "# input image dimensions\n",
        "img_rows, img_cols = 120, 100\n",
        " \n",
        "import os\n",
        " \n",
        "path = './bottles/'\n",
        " \n",
        "files = []\n",
        "# r=root, d=directories, f = files\n",
        "for r, d, f in os.walk(path):\n",
        "    for file in f:\n",
        "        if '.jpg' in file:\n",
        "            files.append(file)\n",
        " \n",
        "X = []\n",
        " \n",
        "db = pd.read_csv(path +'bottles_ground_truth.csv', sep = ';', header = None, skiprows = 1)\n",
        "db = db.fillna(0).to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NuPcOCKgY6-"
      },
      "source": [
        "for e in db[:, 0]:\n",
        "    X.append(np.array(Image.open(path+e).resize((img_cols, img_rows), Image.ANTIALIAS)) )\n",
        "y = db[:, 1:]\n",
        " \n",
        "X = np.array(X)/255\n",
        "y = np.array(y)\n",
        " \n",
        "#x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vGRIbnRA9Yb",
        "outputId": "0e678540-b0f6-4063-ca8c-2368789f99c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(141, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq8MKDEkgc6D",
        "outputId": "925eb388-5f92-4171-9303-bdfdd9c1afd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        " \n",
        "datagen.fit(X)\n",
        " \n",
        "'''\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nx_train = x_train.astype('float32')\\nx_test = x_test.astype('float32')\\nx_train /= 255\\nx_test /= 255\\nprint('x_train shape:', x_train.shape)\\nprint(x_train.shape[0], 'train samples')\\nprint(x_test.shape[0], 'test samples')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yi0v9OORK6V"
      },
      "source": [
        "\n",
        "\n",
        " \n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3),\n",
        "                    activation='relu',\n",
        "                    input_shape=input_shape))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqpLr-imTEar"
      },
      "source": [
        "flow = datagen.flow(X, y, batch_size=36)\n",
        "y = y.astype('int8')\n",
        "#X = X.astype('int8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCn6jOHCglgt",
        "outputId": "c906184b-28e2-46b7-c4f8-c0b61d8ad2b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kf = KFold(n_splits=10)\n",
        "\n",
        "# histograma de ambas as listas. \n",
        "history =[]\n",
        "score =[]\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "     #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "     X_train, X_test = X[train_index], X[test_index]\n",
        "     y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "     # convert class vectors to binary class matrices\n",
        "     #y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "     #y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "     # the data, split between train and test sets\n",
        "     #the data, split between train and test sets\n",
        " \n",
        "     if K.image_data_format() == 'channels_first':\n",
        "          X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
        "          X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
        "          input_shape = (3, img_rows, img_cols)\n",
        "     else:\n",
        "          X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3)\n",
        "          X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3)\n",
        "          input_shape = (img_rows, img_cols, 3)\n",
        " \n",
        "     model = build_model()\n",
        "     model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "     \n",
        "     history.append(model.fit(datagen.flow(X_train, y_train, batch_size=200), epochs=epochs))\n",
        "     score.append(model.evaluate(X_test, y_test, verbose=0))\n",
        "\n",
        "     print('Test loss:', score[-1][0])\n",
        "     print('Test accuracy:', score[-1][1])\n",
        "\n",
        "     \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7f1aaa4e3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8519 - accuracy: 0.0794\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8638 - accuracy: 0.0635\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8332 - accuracy: 0.0397\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8292 - accuracy: 0.0635\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8289 - accuracy: 0.0556\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8348 - accuracy: 0.0317\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8360 - accuracy: 0.0794\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8268 - accuracy: 0.0556\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8345 - accuracy: 0.0317\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8394 - accuracy: 0.0317\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8409 - accuracy: 0.0794\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8300 - accuracy: 0.0556\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8345 - accuracy: 0.0714\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8420 - accuracy: 0.0476\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8219 - accuracy: 0.0873\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8440 - accuracy: 0.0714\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8418 - accuracy: 0.0556\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8245 - accuracy: 0.1032\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8387 - accuracy: 0.1032\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8144 - accuracy: 0.1111\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8231 - accuracy: 0.1190\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8212 - accuracy: 0.0794\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8372 - accuracy: 0.0873\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8360 - accuracy: 0.0873\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8151 - accuracy: 0.0952\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8328 - accuracy: 0.0476\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8386 - accuracy: 0.0952\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8101 - accuracy: 0.1111\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8310 - accuracy: 0.1190\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8273 - accuracy: 0.0794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8312 - accuracy: 0.0873\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8264 - accuracy: 0.1111\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8150 - accuracy: 0.0952\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8434 - accuracy: 0.0635\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8346 - accuracy: 0.0714\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8298 - accuracy: 0.1349\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8044 - accuracy: 0.1587\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8082 - accuracy: 0.1190\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8436 - accuracy: 0.0556\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8121 - accuracy: 0.1111\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8196 - accuracy: 0.1032\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8159 - accuracy: 0.0397\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8134 - accuracy: 0.0952\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8192 - accuracy: 0.1270\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8264 - accuracy: 0.1349\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8038 - accuracy: 0.1746\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8091 - accuracy: 0.1508\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8091 - accuracy: 0.1587\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8193 - accuracy: 0.0952\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8114 - accuracy: 0.1667\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8227 - accuracy: 0.1111\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8292 - accuracy: 0.1111\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8240 - accuracy: 0.1270\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8130 - accuracy: 0.1349\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7901 - accuracy: 0.1825\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8022 - accuracy: 0.1111\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8075 - accuracy: 0.1349\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.8077 - accuracy: 0.1270\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8158 - accuracy: 0.1587\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8034 - accuracy: 0.1667\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8190 - accuracy: 0.1508\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7997 - accuracy: 0.1905\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8000 - accuracy: 0.2381\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8225 - accuracy: 0.1667\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8078 - accuracy: 0.1190\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7981 - accuracy: 0.1667\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8130 - accuracy: 0.1111\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8006 - accuracy: 0.1508\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7988 - accuracy: 0.1825\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7923 - accuracy: 0.1905\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8197 - accuracy: 0.2063\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8095 - accuracy: 0.1429\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8222 - accuracy: 0.1270\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8174 - accuracy: 0.1905\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7930 - accuracy: 0.2063\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8144 - accuracy: 0.2222\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8068 - accuracy: 0.2063\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8053 - accuracy: 0.1825\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7831 - accuracy: 0.2063\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7778 - accuracy: 0.2937\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8084 - accuracy: 0.2143\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8039 - accuracy: 0.2302\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8049 - accuracy: 0.2302\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8026 - accuracy: 0.2222\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7994 - accuracy: 0.1825\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8172 - accuracy: 0.2222\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7759 - accuracy: 0.2302\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7797 - accuracy: 0.2222\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7973 - accuracy: 0.2698\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7891 - accuracy: 0.2381\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7863 - accuracy: 0.2698\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8000 - accuracy: 0.3016\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7860 - accuracy: 0.2857\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8134 - accuracy: 0.2698\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8061 - accuracy: 0.2222\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7855 - accuracy: 0.3333\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8078 - accuracy: 0.2143\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7804 - accuracy: 0.3175\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7959 - accuracy: 0.3333\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7848 - accuracy: 0.2857\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1aaa4acae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test loss: 2.031264066696167\n",
            "Test accuracy: 0.8666666746139526\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8876 - accuracy: 0.2441\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8979 - accuracy: 0.2047\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8912 - accuracy: 0.1811\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9014 - accuracy: 0.1654\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8946 - accuracy: 0.1732\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8904 - accuracy: 0.1811\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8874 - accuracy: 0.1575\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8939 - accuracy: 0.2362\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8881 - accuracy: 0.2283\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8864 - accuracy: 0.2126\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9015 - accuracy: 0.2441\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8912 - accuracy: 0.2126\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8826 - accuracy: 0.2283\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8842 - accuracy: 0.1969\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8898 - accuracy: 0.1732\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8742 - accuracy: 0.2047\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8865 - accuracy: 0.1969\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8822 - accuracy: 0.1732\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8832 - accuracy: 0.1969\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8833 - accuracy: 0.1811\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8805 - accuracy: 0.2520\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8836 - accuracy: 0.2283\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8791 - accuracy: 0.2362\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8895 - accuracy: 0.2205\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8914 - accuracy: 0.2362\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8799 - accuracy: 0.2677\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8826 - accuracy: 0.2441\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8929 - accuracy: 0.2126\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8839 - accuracy: 0.2126\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9040 - accuracy: 0.1811\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8663 - accuracy: 0.2598\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8812 - accuracy: 0.3307\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8886 - accuracy: 0.2756\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8809 - accuracy: 0.2362\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8675 - accuracy: 0.2835\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8706 - accuracy: 0.2913\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8838 - accuracy: 0.2598\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8768 - accuracy: 0.2677\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8985 - accuracy: 0.2992\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8692 - accuracy: 0.2520\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8692 - accuracy: 0.2913\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8666 - accuracy: 0.2913\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8750 - accuracy: 0.2126\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8925 - accuracy: 0.3071\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8877 - accuracy: 0.2756\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8728 - accuracy: 0.3386\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8758 - accuracy: 0.2913\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8615 - accuracy: 0.2520\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8703 - accuracy: 0.3071\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8755 - accuracy: 0.3465\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8748 - accuracy: 0.2992\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8745 - accuracy: 0.2913\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8937 - accuracy: 0.2835\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8709 - accuracy: 0.2520\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8776 - accuracy: 0.3150\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8383 - accuracy: 0.3701\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8776 - accuracy: 0.2992\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8683 - accuracy: 0.3386\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8456 - accuracy: 0.4252\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8615 - accuracy: 0.3937\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8910 - accuracy: 0.2913\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8662 - accuracy: 0.3465\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8876 - accuracy: 0.3386\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8714 - accuracy: 0.2992\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8799 - accuracy: 0.3858\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8737 - accuracy: 0.3150\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8699 - accuracy: 0.3465\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8594 - accuracy: 0.3937\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8909 - accuracy: 0.3858\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8633 - accuracy: 0.4173\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8544 - accuracy: 0.3543\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8571 - accuracy: 0.4016\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8733 - accuracy: 0.3071\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8655 - accuracy: 0.3780\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8754 - accuracy: 0.3386\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8682 - accuracy: 0.3622\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8486 - accuracy: 0.3937\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8642 - accuracy: 0.3701\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8473 - accuracy: 0.4646\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8497 - accuracy: 0.3937\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8656 - accuracy: 0.4016\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8477 - accuracy: 0.4016\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8746 - accuracy: 0.3701\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8727 - accuracy: 0.4094\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8519 - accuracy: 0.4488\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8522 - accuracy: 0.4488\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8623 - accuracy: 0.3701\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8366 - accuracy: 0.4331\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8638 - accuracy: 0.3622\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8530 - accuracy: 0.4173\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8593 - accuracy: 0.4331\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8618 - accuracy: 0.4724\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8717 - accuracy: 0.4488\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8406 - accuracy: 0.4803\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8514 - accuracy: 0.4331\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8399 - accuracy: 0.4173\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8398 - accuracy: 0.3937\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8550 - accuracy: 0.4567\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8679 - accuracy: 0.4488\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8435 - accuracy: 0.4331\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1aa9241b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test loss: 1.3213565349578857\n",
            "Test accuracy: 0.7142857313156128\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8030 - accuracy: 0.1260\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7844 - accuracy: 0.1575\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7934 - accuracy: 0.1654\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7881 - accuracy: 0.0866\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7939 - accuracy: 0.1575\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7918 - accuracy: 0.1181\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7874 - accuracy: 0.1102\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7749 - accuracy: 0.1732\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7841 - accuracy: 0.1732\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7926 - accuracy: 0.1496\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7816 - accuracy: 0.1890\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7879 - accuracy: 0.1339\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7764 - accuracy: 0.1575\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7882 - accuracy: 0.1575\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7736 - accuracy: 0.1417\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7851 - accuracy: 0.1969\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7884 - accuracy: 0.1575\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7668 - accuracy: 0.2283\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7766 - accuracy: 0.1890\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7762 - accuracy: 0.2283\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7812 - accuracy: 0.1811\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7718 - accuracy: 0.2283\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7830 - accuracy: 0.1969\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7685 - accuracy: 0.2126\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7929 - accuracy: 0.1260\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7766 - accuracy: 0.1811\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7787 - accuracy: 0.1732\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7790 - accuracy: 0.1890\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7879 - accuracy: 0.1969\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7663 - accuracy: 0.1811\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7957 - accuracy: 0.1890\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7761 - accuracy: 0.1654\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7735 - accuracy: 0.2126\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7774 - accuracy: 0.1969\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7756 - accuracy: 0.2441\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7651 - accuracy: 0.3071\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7740 - accuracy: 0.2126\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7568 - accuracy: 0.2362\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7709 - accuracy: 0.2205\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7803 - accuracy: 0.2126\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7717 - accuracy: 0.2205\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7870 - accuracy: 0.2677\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7593 - accuracy: 0.2598\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7675 - accuracy: 0.2205\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7749 - accuracy: 0.2520\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7619 - accuracy: 0.3071\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7650 - accuracy: 0.2677\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7694 - accuracy: 0.2598\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7570 - accuracy: 0.2598\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7509 - accuracy: 0.2677\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7702 - accuracy: 0.2283\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7676 - accuracy: 0.1654\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7523 - accuracy: 0.3228\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7549 - accuracy: 0.2362\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7745 - accuracy: 0.2520\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7703 - accuracy: 0.2598\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7555 - accuracy: 0.2992\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7771 - accuracy: 0.2677\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7677 - accuracy: 0.2520\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7658 - accuracy: 0.3071\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.7653 - accuracy: 0.2520\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7696 - accuracy: 0.2126\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7567 - accuracy: 0.2835\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7631 - accuracy: 0.2913\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7551 - accuracy: 0.2756\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7600 - accuracy: 0.2441\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7516 - accuracy: 0.2992\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7719 - accuracy: 0.2362\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7615 - accuracy: 0.2677\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7717 - accuracy: 0.3780\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7540 - accuracy: 0.3228\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7622 - accuracy: 0.3150\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7439 - accuracy: 0.3780\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7578 - accuracy: 0.2835\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7588 - accuracy: 0.2992\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7614 - accuracy: 0.2598\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7750 - accuracy: 0.3386\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7515 - accuracy: 0.2835\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7659 - accuracy: 0.3150\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7527 - accuracy: 0.2992\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7756 - accuracy: 0.2913\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7460 - accuracy: 0.3307\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7495 - accuracy: 0.4016\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7667 - accuracy: 0.3071\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7651 - accuracy: 0.2598\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7668 - accuracy: 0.3071\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7716 - accuracy: 0.3150\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7491 - accuracy: 0.3465\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7469 - accuracy: 0.3622\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7452 - accuracy: 0.3071\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7441 - accuracy: 0.3780\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7753 - accuracy: 0.3386\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7751 - accuracy: 0.3780\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7647 - accuracy: 0.3937\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7550 - accuracy: 0.2835\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7635 - accuracy: 0.3780\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7634 - accuracy: 0.3543\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7738 - accuracy: 0.3228\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7595 - accuracy: 0.3701\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7488 - accuracy: 0.4094\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1aa7f74a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test loss: 2.3387646675109863\n",
            "Test accuracy: 0.7142857313156128\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8208 - accuracy: 0.1339\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8256 - accuracy: 0.0394\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8084 - accuracy: 0.1260\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8099 - accuracy: 0.1024\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7975 - accuracy: 0.1024\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8033 - accuracy: 0.1024\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8127 - accuracy: 0.0787\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7922 - accuracy: 0.1102\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7984 - accuracy: 0.0787\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7981 - accuracy: 0.1260\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7937 - accuracy: 0.1260\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8023 - accuracy: 0.1260\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7909 - accuracy: 0.1575\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7976 - accuracy: 0.1024\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7975 - accuracy: 0.1575\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8178 - accuracy: 0.1339\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8109 - accuracy: 0.1339\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8185 - accuracy: 0.0945\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.8113 - accuracy: 0.0866\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7737 - accuracy: 0.1732\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7955 - accuracy: 0.1102\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8095 - accuracy: 0.1181\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7732 - accuracy: 0.1732\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7911 - accuracy: 0.1890\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7874 - accuracy: 0.1575\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7937 - accuracy: 0.1575\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7771 - accuracy: 0.1024\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8012 - accuracy: 0.1102\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7853 - accuracy: 0.1811\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7818 - accuracy: 0.0945\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7943 - accuracy: 0.1260\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7996 - accuracy: 0.1417\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.7935 - accuracy: 0.1575\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7734 - accuracy: 0.1260\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8008 - accuracy: 0.1496\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7965 - accuracy: 0.1496\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7883 - accuracy: 0.1496\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7898 - accuracy: 0.0866\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8133 - accuracy: 0.1339\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7786 - accuracy: 0.1339\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7833 - accuracy: 0.1496\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7658 - accuracy: 0.1575\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7702 - accuracy: 0.2283\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7882 - accuracy: 0.1890\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7970 - accuracy: 0.1575\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7771 - accuracy: 0.1496\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7880 - accuracy: 0.2047\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7946 - accuracy: 0.2283\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7841 - accuracy: 0.1654\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7882 - accuracy: 0.2283\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7873 - accuracy: 0.1969\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7761 - accuracy: 0.1417\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7688 - accuracy: 0.2441\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7723 - accuracy: 0.1732\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7589 - accuracy: 0.2835\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7698 - accuracy: 0.2205\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7740 - accuracy: 0.2047\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7644 - accuracy: 0.1969\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7702 - accuracy: 0.2283\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7658 - accuracy: 0.2283\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7877 - accuracy: 0.2047\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7500 - accuracy: 0.2677\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7615 - accuracy: 0.2520\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7625 - accuracy: 0.2913\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7666 - accuracy: 0.3071\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7578 - accuracy: 0.2835\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7695 - accuracy: 0.2441\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7563 - accuracy: 0.2205\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7697 - accuracy: 0.2520\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7587 - accuracy: 0.1969\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7703 - accuracy: 0.2362\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7678 - accuracy: 0.3150\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7534 - accuracy: 0.3150\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7786 - accuracy: 0.2283\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.7619 - accuracy: 0.2677\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7833 - accuracy: 0.2835\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7883 - accuracy: 0.2047\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7843 - accuracy: 0.2835\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7594 - accuracy: 0.2520\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7322 - accuracy: 0.2992\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7607 - accuracy: 0.2677\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7620 - accuracy: 0.2756\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7570 - accuracy: 0.2677\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7498 - accuracy: 0.3307\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7711 - accuracy: 0.2992\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7556 - accuracy: 0.2835\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7597 - accuracy: 0.2598\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7737 - accuracy: 0.2913\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7559 - accuracy: 0.2598\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7506 - accuracy: 0.2913\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7374 - accuracy: 0.4094\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7543 - accuracy: 0.2992\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7601 - accuracy: 0.3543\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7786 - accuracy: 0.3228\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7461 - accuracy: 0.3543\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7522 - accuracy: 0.3701\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7665 - accuracy: 0.3701\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7280 - accuracy: 0.3465\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.7530 - accuracy: 0.3937\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7438 - accuracy: 0.3543\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1aa6e6abf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test loss: 2.354401111602783\n",
            "Test accuracy: 0.6428571343421936\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9391 - accuracy: 0.0551\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9458 - accuracy: 0.0394\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9194 - accuracy: 0.0709\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9446 - accuracy: 0.0315\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9375 - accuracy: 0.0787\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9000 - accuracy: 0.0709\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9232 - accuracy: 0.1024\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9283 - accuracy: 0.1024\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9127 - accuracy: 0.1654\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9257 - accuracy: 0.0866\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9156 - accuracy: 0.0709\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9285 - accuracy: 0.1024\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9446 - accuracy: 0.0787\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9267 - accuracy: 0.0709\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9139 - accuracy: 0.1181\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9265 - accuracy: 0.1181\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9170 - accuracy: 0.1181\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9281 - accuracy: 0.0472\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9276 - accuracy: 0.1181\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9196 - accuracy: 0.0787\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9560 - accuracy: 0.0945\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9264 - accuracy: 0.0866\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9400 - accuracy: 0.0945\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9043 - accuracy: 0.1024\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9283 - accuracy: 0.0394\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9258 - accuracy: 0.1260\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9183 - accuracy: 0.1575\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9049 - accuracy: 0.1102\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9209 - accuracy: 0.1417\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9199 - accuracy: 0.1181\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9202 - accuracy: 0.1339\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9257 - accuracy: 0.1024\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9151 - accuracy: 0.1260\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9059 - accuracy: 0.0866\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9205 - accuracy: 0.1024\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9125 - accuracy: 0.1654\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8997 - accuracy: 0.1417\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9212 - accuracy: 0.1339\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9218 - accuracy: 0.1260\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9031 - accuracy: 0.2205\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9101 - accuracy: 0.1339\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9192 - accuracy: 0.1417\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9114 - accuracy: 0.1496\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9315 - accuracy: 0.1102\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8891 - accuracy: 0.2047\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9155 - accuracy: 0.1969\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9242 - accuracy: 0.1575\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9086 - accuracy: 0.1260\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9094 - accuracy: 0.1654\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8916 - accuracy: 0.1654\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8941 - accuracy: 0.2047\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9049 - accuracy: 0.2126\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9234 - accuracy: 0.1181\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9085 - accuracy: 0.2205\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9007 - accuracy: 0.2126\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9105 - accuracy: 0.1969\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9108 - accuracy: 0.1890\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9206 - accuracy: 0.2205\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9129 - accuracy: 0.1732\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8893 - accuracy: 0.2362\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9053 - accuracy: 0.2677\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8885 - accuracy: 0.1732\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9066 - accuracy: 0.2047\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9187 - accuracy: 0.1969\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8999 - accuracy: 0.2283\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9054 - accuracy: 0.2441\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8695 - accuracy: 0.3228\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9024 - accuracy: 0.2283\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8994 - accuracy: 0.1811\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8897 - accuracy: 0.2913\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8893 - accuracy: 0.2677\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8859 - accuracy: 0.2126\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9044 - accuracy: 0.2756\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8985 - accuracy: 0.2598\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8989 - accuracy: 0.3228\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9212 - accuracy: 0.2520\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9135 - accuracy: 0.2598\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8826 - accuracy: 0.1890\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8800 - accuracy: 0.3228\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9127 - accuracy: 0.2756\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8855 - accuracy: 0.2756\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8841 - accuracy: 0.2205\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9089 - accuracy: 0.2126\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8803 - accuracy: 0.2677\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8926 - accuracy: 0.3386\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8844 - accuracy: 0.2362\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9015 - accuracy: 0.2441\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8761 - accuracy: 0.2835\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8951 - accuracy: 0.3071\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8947 - accuracy: 0.3307\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8945 - accuracy: 0.3543\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8848 - accuracy: 0.2835\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8824 - accuracy: 0.3071\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8958 - accuracy: 0.2835\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8953 - accuracy: 0.2677\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8805 - accuracy: 0.3937\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8907 - accuracy: 0.2992\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8915 - accuracy: 0.3228\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9094 - accuracy: 0.2756\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8874 - accuracy: 0.3307\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1aaa55da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test loss: 1.1585350036621094\n",
            "Test accuracy: 0.7857142686843872\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8702 - accuracy: 0.1260\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8696 - accuracy: 0.1024\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8653 - accuracy: 0.0945\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8768 - accuracy: 0.1496\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8611 - accuracy: 0.1181\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8723 - accuracy: 0.0787\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8648 - accuracy: 0.1575\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8623 - accuracy: 0.1732\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8788 - accuracy: 0.1575\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8681 - accuracy: 0.0866\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8610 - accuracy: 0.1102\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8742 - accuracy: 0.1496\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8627 - accuracy: 0.1260\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8709 - accuracy: 0.1732\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8609 - accuracy: 0.1339\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8422 - accuracy: 0.1260\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8490 - accuracy: 0.1654\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8515 - accuracy: 0.1890\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8407 - accuracy: 0.1417\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8528 - accuracy: 0.1654\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8600 - accuracy: 0.1496\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8570 - accuracy: 0.2126\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8369 - accuracy: 0.2598\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8164 - accuracy: 0.2520\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8442 - accuracy: 0.1890\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8315 - accuracy: 0.1811\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8509 - accuracy: 0.1969\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8514 - accuracy: 0.1339\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8352 - accuracy: 0.1732\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8579 - accuracy: 0.1811\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8210 - accuracy: 0.3228\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8415 - accuracy: 0.2205\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8493 - accuracy: 0.2283\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8462 - accuracy: 0.2362\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8238 - accuracy: 0.1732\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8270 - accuracy: 0.2441\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8532 - accuracy: 0.2126\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8452 - accuracy: 0.2835\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8413 - accuracy: 0.1732\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8427 - accuracy: 0.1732\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8378 - accuracy: 0.2126\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8342 - accuracy: 0.2362\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8453 - accuracy: 0.2441\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8274 - accuracy: 0.2441\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8415 - accuracy: 0.2283\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8269 - accuracy: 0.2756\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8217 - accuracy: 0.2756\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8330 - accuracy: 0.2283\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8267 - accuracy: 0.2362\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8356 - accuracy: 0.2598\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8402 - accuracy: 0.2835\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8068 - accuracy: 0.2677\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8177 - accuracy: 0.3071\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8308 - accuracy: 0.3071\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8170 - accuracy: 0.2913\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8074 - accuracy: 0.3307\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8127 - accuracy: 0.3858\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8273 - accuracy: 0.3071\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8394 - accuracy: 0.3071\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8185 - accuracy: 0.3701\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8186 - accuracy: 0.3228\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8131 - accuracy: 0.3622\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8170 - accuracy: 0.3622\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7912 - accuracy: 0.3228\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8046 - accuracy: 0.3622\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8112 - accuracy: 0.3780\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8044 - accuracy: 0.3622\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8389 - accuracy: 0.3780\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8066 - accuracy: 0.3937\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8017 - accuracy: 0.3701\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8137 - accuracy: 0.3543\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8115 - accuracy: 0.3543\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8258 - accuracy: 0.3937\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7982 - accuracy: 0.3071\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8010 - accuracy: 0.3701\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8156 - accuracy: 0.3858\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7989 - accuracy: 0.4646\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8261 - accuracy: 0.3701\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8148 - accuracy: 0.4094\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8046 - accuracy: 0.4331\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8162 - accuracy: 0.3071\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7965 - accuracy: 0.4252\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8073 - accuracy: 0.4331\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8208 - accuracy: 0.4016\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7900 - accuracy: 0.4016\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8244 - accuracy: 0.3701\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8146 - accuracy: 0.4409\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8037 - accuracy: 0.4252\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8231 - accuracy: 0.4567\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7979 - accuracy: 0.4882\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7977 - accuracy: 0.4724\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7984 - accuracy: 0.4488\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8189 - accuracy: 0.4173\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8001 - accuracy: 0.3780\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7978 - accuracy: 0.4409\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7840 - accuracy: 0.4646\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8144 - accuracy: 0.4961\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7997 - accuracy: 0.4646\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7969 - accuracy: 0.5118\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8079 - accuracy: 0.4803\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1aabebb0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test loss: 1.7661285400390625\n",
            "Test accuracy: 0.6428571343421936\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7725 - accuracy: 0.0945\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7679 - accuracy: 0.0709\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7740 - accuracy: 0.0866\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7822 - accuracy: 0.0709\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7823 - accuracy: 0.0394\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7725 - accuracy: 0.0787\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7993 - accuracy: 0.0236\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7835 - accuracy: 0.0551\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7779 - accuracy: 0.0630\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7727 - accuracy: 0.0709\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7780 - accuracy: 0.0630\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7759 - accuracy: 0.0945\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7711 - accuracy: 0.0945\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7816 - accuracy: 0.0630\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7872 - accuracy: 0.0394\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7677 - accuracy: 0.1102\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7705 - accuracy: 0.0787\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7829 - accuracy: 0.0787\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7793 - accuracy: 0.0709\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7763 - accuracy: 0.0709\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.7702 - accuracy: 0.0866\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7637 - accuracy: 0.0866\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7790 - accuracy: 0.0866\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7675 - accuracy: 0.0866\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7819 - accuracy: 0.0630\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7756 - accuracy: 0.0945\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7590 - accuracy: 0.1260\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7678 - accuracy: 0.0551\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7715 - accuracy: 0.1339\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7888 - accuracy: 0.0157\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7866 - accuracy: 0.0551\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7758 - accuracy: 0.0630\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7761 - accuracy: 0.0866\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7744 - accuracy: 0.0866\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7689 - accuracy: 0.0787\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7766 - accuracy: 0.1024\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7725 - accuracy: 0.1024\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7696 - accuracy: 0.0866\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.7570 - accuracy: 0.1496\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7690 - accuracy: 0.1024\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7676 - accuracy: 0.1260\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7624 - accuracy: 0.1024\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7670 - accuracy: 0.1102\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7726 - accuracy: 0.1339\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7670 - accuracy: 0.0787\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7772 - accuracy: 0.0866\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7672 - accuracy: 0.1102\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7670 - accuracy: 0.1496\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7638 - accuracy: 0.1102\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7617 - accuracy: 0.1260\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7698 - accuracy: 0.0945\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7668 - accuracy: 0.1260\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7570 - accuracy: 0.1654\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7599 - accuracy: 0.0787\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7626 - accuracy: 0.0787\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7705 - accuracy: 0.0709\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7585 - accuracy: 0.1496\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7670 - accuracy: 0.1575\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7687 - accuracy: 0.1417\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7603 - accuracy: 0.1496\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7635 - accuracy: 0.1260\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7662 - accuracy: 0.0866\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7740 - accuracy: 0.0866\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7668 - accuracy: 0.0945\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7691 - accuracy: 0.1496\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7704 - accuracy: 0.1181\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7630 - accuracy: 0.1496\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7591 - accuracy: 0.1181\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7689 - accuracy: 0.1496\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.7542 - accuracy: 0.1654\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7651 - accuracy: 0.1732\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7642 - accuracy: 0.1654\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7789 - accuracy: 0.1339\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7483 - accuracy: 0.1654\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7585 - accuracy: 0.1339\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7722 - accuracy: 0.0630\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7597 - accuracy: 0.1654\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7750 - accuracy: 0.1732\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7491 - accuracy: 0.1811\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7743 - accuracy: 0.1575\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7587 - accuracy: 0.1732\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7570 - accuracy: 0.1575\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7555 - accuracy: 0.2126\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7439 - accuracy: 0.1575\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7616 - accuracy: 0.1496\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7447 - accuracy: 0.2126\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7732 - accuracy: 0.1732\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7557 - accuracy: 0.1890\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7654 - accuracy: 0.1732\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7551 - accuracy: 0.1890\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7655 - accuracy: 0.1890\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7588 - accuracy: 0.1969\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7576 - accuracy: 0.2126\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7463 - accuracy: 0.1575\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7639 - accuracy: 0.1339\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7655 - accuracy: 0.1969\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7507 - accuracy: 0.2441\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7645 - accuracy: 0.2362\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7567 - accuracy: 0.2835\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7758 - accuracy: 0.1654\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1aad28bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test loss: 2.52534818649292\n",
            "Test accuracy: 0.2857142984867096\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8644 - accuracy: 0.2205\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8630 - accuracy: 0.2047\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8746 - accuracy: 0.2047\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8590 - accuracy: 0.1969\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8501 - accuracy: 0.2835\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8444 - accuracy: 0.2756\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8620 - accuracy: 0.2441\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8575 - accuracy: 0.2441\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8428 - accuracy: 0.3307\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8516 - accuracy: 0.2835\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8479 - accuracy: 0.3228\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8694 - accuracy: 0.2835\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8442 - accuracy: 0.2913\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8631 - accuracy: 0.3386\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8674 - accuracy: 0.3307\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8441 - accuracy: 0.3465\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8309 - accuracy: 0.3228\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8326 - accuracy: 0.3150\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8235 - accuracy: 0.3386\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8283 - accuracy: 0.3858\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8555 - accuracy: 0.2992\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8230 - accuracy: 0.2992\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8509 - accuracy: 0.3465\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8414 - accuracy: 0.3465\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8313 - accuracy: 0.3858\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8549 - accuracy: 0.2992\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8723 - accuracy: 0.3622\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8067 - accuracy: 0.4173\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8433 - accuracy: 0.3386\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8542 - accuracy: 0.3858\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8185 - accuracy: 0.4409\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8370 - accuracy: 0.3386\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8537 - accuracy: 0.4016\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8257 - accuracy: 0.4016\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8731 - accuracy: 0.3937\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8680 - accuracy: 0.4173\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8416 - accuracy: 0.3543\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8554 - accuracy: 0.3937\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8210 - accuracy: 0.4567\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8620 - accuracy: 0.4331\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8449 - accuracy: 0.4016\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8124 - accuracy: 0.4016\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8302 - accuracy: 0.4016\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8377 - accuracy: 0.4094\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8320 - accuracy: 0.4882\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8211 - accuracy: 0.4646\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8057 - accuracy: 0.4331\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8029 - accuracy: 0.4488\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8138 - accuracy: 0.4488\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8301 - accuracy: 0.5276\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8342 - accuracy: 0.4882\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8171 - accuracy: 0.5354\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8464 - accuracy: 0.4173\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8183 - accuracy: 0.5197\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8340 - accuracy: 0.5039\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8291 - accuracy: 0.5118\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8096 - accuracy: 0.5039\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8095 - accuracy: 0.4803\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8248 - accuracy: 0.5433\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8310 - accuracy: 0.4646\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7971 - accuracy: 0.5197\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8265 - accuracy: 0.5039\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8329 - accuracy: 0.4409\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8011 - accuracy: 0.5276\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8036 - accuracy: 0.4803\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8152 - accuracy: 0.5039\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8006 - accuracy: 0.4961\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7831 - accuracy: 0.5433\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8131 - accuracy: 0.5512\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8239 - accuracy: 0.5433\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8403 - accuracy: 0.5669\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8462 - accuracy: 0.4803\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7927 - accuracy: 0.5276\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7907 - accuracy: 0.4961\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8228 - accuracy: 0.5748\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7719 - accuracy: 0.5354\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8083 - accuracy: 0.5512\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8252 - accuracy: 0.5591\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8280 - accuracy: 0.5197\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8006 - accuracy: 0.5276\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8107 - accuracy: 0.5591\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7971 - accuracy: 0.5512\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8151 - accuracy: 0.5197\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7959 - accuracy: 0.5354\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7945 - accuracy: 0.5906\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7896 - accuracy: 0.5354\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7948 - accuracy: 0.5827\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7841 - accuracy: 0.5906\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7967 - accuracy: 0.5512\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8175 - accuracy: 0.5906\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8063 - accuracy: 0.5748\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7869 - accuracy: 0.5354\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7545 - accuracy: 0.5984\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7850 - accuracy: 0.5512\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7948 - accuracy: 0.5512\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7927 - accuracy: 0.5984\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7817 - accuracy: 0.5512\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8095 - accuracy: 0.5984\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8163 - accuracy: 0.5827\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.7918 - accuracy: 0.5906\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1ab1b26598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test loss: 1.4725786447525024\n",
            "Test accuracy: 0.5714285969734192\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8790 - accuracy: 0.1654\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8528 - accuracy: 0.1890\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8583 - accuracy: 0.1732\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8350 - accuracy: 0.1969\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8625 - accuracy: 0.1811\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8616 - accuracy: 0.1969\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8663 - accuracy: 0.1969\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8577 - accuracy: 0.2126\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8549 - accuracy: 0.2598\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8577 - accuracy: 0.2598\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8327 - accuracy: 0.2598\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.8489 - accuracy: 0.1811\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8353 - accuracy: 0.2205\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8510 - accuracy: 0.2047\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8158 - accuracy: 0.2362\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8246 - accuracy: 0.3386\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8357 - accuracy: 0.2047\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8699 - accuracy: 0.2126\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8197 - accuracy: 0.2756\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8284 - accuracy: 0.2520\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8132 - accuracy: 0.2913\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8411 - accuracy: 0.3465\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8553 - accuracy: 0.2677\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8440 - accuracy: 0.2835\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8488 - accuracy: 0.2283\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8440 - accuracy: 0.2598\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8386 - accuracy: 0.3307\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8268 - accuracy: 0.3071\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8423 - accuracy: 0.2835\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8486 - accuracy: 0.3307\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8044 - accuracy: 0.3937\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8256 - accuracy: 0.3228\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8370 - accuracy: 0.3543\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8467 - accuracy: 0.2677\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8017 - accuracy: 0.3937\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8158 - accuracy: 0.3071\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8466 - accuracy: 0.3780\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8303 - accuracy: 0.3150\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8189 - accuracy: 0.2913\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7951 - accuracy: 0.4173\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8282 - accuracy: 0.2913\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8161 - accuracy: 0.3937\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8251 - accuracy: 0.3858\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8096 - accuracy: 0.4173\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8209 - accuracy: 0.3543\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8234 - accuracy: 0.4094\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8237 - accuracy: 0.3543\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8271 - accuracy: 0.3701\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8237 - accuracy: 0.3622\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8459 - accuracy: 0.3465\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8259 - accuracy: 0.4094\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8185 - accuracy: 0.4252\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8246 - accuracy: 0.4094\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8469 - accuracy: 0.3150\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7981 - accuracy: 0.3780\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.8012 - accuracy: 0.4646\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8172 - accuracy: 0.4252\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8355 - accuracy: 0.4331\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8467 - accuracy: 0.4016\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7998 - accuracy: 0.4567\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8108 - accuracy: 0.4331\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8271 - accuracy: 0.3937\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8116 - accuracy: 0.4724\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8155 - accuracy: 0.4094\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8128 - accuracy: 0.4094\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8163 - accuracy: 0.4331\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7887 - accuracy: 0.4882\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8137 - accuracy: 0.4803\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8199 - accuracy: 0.4016\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8016 - accuracy: 0.4331\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8070 - accuracy: 0.4409\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8033 - accuracy: 0.4724\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8022 - accuracy: 0.4331\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8032 - accuracy: 0.4646\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8048 - accuracy: 0.4646\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8092 - accuracy: 0.5039\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8028 - accuracy: 0.4646\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7996 - accuracy: 0.4724\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7888 - accuracy: 0.4882\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8116 - accuracy: 0.4961\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8041 - accuracy: 0.4724\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8081 - accuracy: 0.4961\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7925 - accuracy: 0.4882\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7906 - accuracy: 0.4803\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8109 - accuracy: 0.4567\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7839 - accuracy: 0.4961\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7862 - accuracy: 0.4882\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7992 - accuracy: 0.5118\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7897 - accuracy: 0.4961\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7623 - accuracy: 0.5827\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8025 - accuracy: 0.5433\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7959 - accuracy: 0.5039\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7893 - accuracy: 0.5039\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8061 - accuracy: 0.5197\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7888 - accuracy: 0.5118\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8049 - accuracy: 0.5354\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7933 - accuracy: 0.5591\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7764 - accuracy: 0.5197\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7859 - accuracy: 0.5433\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.7982 - accuracy: 0.5197\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1aac062c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test loss: 1.7572575807571411\n",
            "Test accuracy: 0.4285714328289032\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9136 - accuracy: 0.0787\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9032 - accuracy: 0.0630\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9197 - accuracy: 0.0315\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9055 - accuracy: 0.0394\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9067 - accuracy: 0.0472\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8894 - accuracy: 0.0709\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9028 - accuracy: 0.0315\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9003 - accuracy: 0.0709\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9042 - accuracy: 0.1102\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8886 - accuracy: 0.0630\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8931 - accuracy: 0.1339\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8969 - accuracy: 0.0866\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8793 - accuracy: 0.0866\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8919 - accuracy: 0.0709\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9060 - accuracy: 0.0551\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.8641 - accuracy: 0.0709\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9051 - accuracy: 0.0866\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8913 - accuracy: 0.0472\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8849 - accuracy: 0.1024\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8918 - accuracy: 0.0551\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8981 - accuracy: 0.1181\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8698 - accuracy: 0.1260\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8866 - accuracy: 0.1417\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8703 - accuracy: 0.1811\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8866 - accuracy: 0.0866\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8770 - accuracy: 0.1417\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8900 - accuracy: 0.1024\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8881 - accuracy: 0.0866\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8860 - accuracy: 0.1024\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9002 - accuracy: 0.1181\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8893 - accuracy: 0.1102\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8951 - accuracy: 0.0787\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8795 - accuracy: 0.1339\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8711 - accuracy: 0.2283\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8793 - accuracy: 0.1732\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8745 - accuracy: 0.1339\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8773 - accuracy: 0.1732\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8665 - accuracy: 0.1890\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8612 - accuracy: 0.1890\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8706 - accuracy: 0.1339\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8739 - accuracy: 0.1575\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8740 - accuracy: 0.1732\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8697 - accuracy: 0.1496\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8663 - accuracy: 0.1890\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8615 - accuracy: 0.1575\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8679 - accuracy: 0.1969\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8647 - accuracy: 0.1969\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8565 - accuracy: 0.1654\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8746 - accuracy: 0.1969\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8868 - accuracy: 0.1654\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8596 - accuracy: 0.2441\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8590 - accuracy: 0.2441\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8684 - accuracy: 0.1732\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8676 - accuracy: 0.1890\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8629 - accuracy: 0.2047\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8794 - accuracy: 0.2126\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8583 - accuracy: 0.1496\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8464 - accuracy: 0.2598\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8623 - accuracy: 0.2598\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8729 - accuracy: 0.2283\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8548 - accuracy: 0.2756\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8639 - accuracy: 0.2598\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8822 - accuracy: 0.1811\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8503 - accuracy: 0.2283\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8637 - accuracy: 0.2756\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8659 - accuracy: 0.2205\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8563 - accuracy: 0.2756\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8663 - accuracy: 0.2520\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8494 - accuracy: 0.3228\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8728 - accuracy: 0.3071\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8639 - accuracy: 0.2598\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8408 - accuracy: 0.2520\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8617 - accuracy: 0.2756\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8647 - accuracy: 0.2677\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8434 - accuracy: 0.3071\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8596 - accuracy: 0.3386\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8561 - accuracy: 0.2362\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8662 - accuracy: 0.2126\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8484 - accuracy: 0.2756\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8642 - accuracy: 0.3071\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8385 - accuracy: 0.3622\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8531 - accuracy: 0.3386\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8483 - accuracy: 0.3465\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8595 - accuracy: 0.3307\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8392 - accuracy: 0.2913\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8585 - accuracy: 0.3622\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8507 - accuracy: 0.3307\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8776 - accuracy: 0.3465\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8521 - accuracy: 0.3071\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8534 - accuracy: 0.3780\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8557 - accuracy: 0.3228\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8380 - accuracy: 0.3622\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8633 - accuracy: 0.3622\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8382 - accuracy: 0.3465\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8374 - accuracy: 0.3543\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8341 - accuracy: 0.3622\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8365 - accuracy: 0.2992\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8192 - accuracy: 0.4016\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8428 - accuracy: 0.3780\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8302 - accuracy: 0.4094\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1ab1a766a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Test loss: 1.4501491785049438\n",
            "Test accuracy: 0.7142857313156128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyeuFEJhK0ia",
        "outputId": "2015072f-aefc-46bb-e3e2-939139071c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(71, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLKEpkAhK55M",
        "outputId": "501364d5-9389-49d7-d79c-e34b2ac0b9f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1thp5fJdKogY",
        "outputId": "32c9af43-a7e2-4ca9-eae1-ffbe4f7231ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "'''\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accuracy'], loc='upper left')\n",
        "plt.show()\n",
        " \n",
        "# summarize history for loss\n",
        " \n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss'], loc='upper left')\n",
        "plt.show()\n",
        "'''\n",
        "\n",
        "model.save(\"model.h5\")\n",
        "\n",
        "plt.hist([score[e][0] for e in range(10)])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# acuracia: \n",
        "plt.hist([score[e][1] for e in range(10)])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accuracy'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# acuracia do treino \n",
        "#print(np.mean([history[e].history['accuracy'] for e in range(10)]))\n",
        "\n",
        "# conjunto de teste\n",
        "print('Media conjunto de teste',np.mean([score[e][0] for e in range(10)]))\n",
        "print('Media conjunto de treinamento',np.mean([score[e][0] for e in range(10)]))\n",
        "\n",
        "print('desvio padrao conjunto de teste',np.std([score[e][1] for e in range(10)]))\n",
        "print('desvio padrao conjunto de treinamento:',np.std([score[e][1] for e in range(10)]))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: [2.031264066696167, 0.8666666746139526]\n",
            "Test accuracy: [1.3213565349578857, 0.7142857313156128]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEaCAYAAAD+E0veAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVQUd7o+8KfpZlVUoAXEjQFcUI8Jy4yoUYz0KCNM9DoSr47GLTGR5CrJDFfjErIaIjExIpl4FHDUJEImM5nkGpe0y8ElZETERETBYDI4LtgsAcEGmq7fH4nfny2ihdLV0D6fczyHqvp21ft2tzx0VXWVSpIkCURERAAcbF0AERF1HAwFIiISGApERCQwFIiISGAoEBGRwFAgIiKBoUAPDH9/f7z++utteoxKpcL27dutVBFRx8NQICIigaFAZIcaGxttXQJ1UgwFsplx48ZhwYIFWLlyJby9vdGjRw+sWLECZrMZr776Knx8fNCzZ0+sWLHC4nG1tbV4+umn0bNnTzg7OyM8PBx79+61GHPy5EmMGjUKzs7OGDBgALKzs1ts/9q1a1iyZAl69+4NNzc3hISE4O9//3ubeqiqqsKsWbPQr18/uLq6YtCgQVi7di1uvVBAVlYWwsLC4OLiAi8vL/zud79DVVWVWJ6WloYhQ4bA2dkZ3t7e+MMf/iCW3W6315NPPolx48a1eC5XrVqFXr16oV+/fgCAjz76CCNGjED37t2h1WoRExOD4uJii3WVl5dj3rx58PHxgYuLCwYNGoSMjAxIkoSAgACsXr3aYnxdXR26deuGbdu2tem5os6BoUA29be//Q1NTU04fPgw3nnnHaxevRoxMTG4du0aDh06hLfffhurV6/Grl27xGPmz5+PPXv2YPv27SgoKMDo0aMRGxuLM2fOAACuX7+OSZMmoUePHvjXv/6FrVu3IiUlBeXl5WIdkiTh97//PU6ePImsrCycOnUKixYtwn//939j3759sutvaGjAsGHD8Nlnn+H06dNYtWoVkpKSsGXLFjEmMzMTs2bNwpQpU5Cfn48DBw4gOjoazc3NAICkpCQsXboU8fHx+O6777B7926Ehoa2+bnMzs7G1atXsW/fPnz11VeivpUrVyI/Px9fffUV1Go1YmJixCeJ69evIzIyEidPnsSHH36I06dPIzU1FW5ublCpVHjqqaeQnp5uEXI7duyARqNBXFxcm2ukTkAispHIyEjpoYcespg3ZMgQadiwYRbzhg8fLv3pT3+SJEmSSkpKJADSzp07LcaEhIRI8+bNkyRJkjZt2iR16dJFqqysFMu/++47CYD02muvSZIkSQcOHJCcnZ2l6upqi/XMmzdPmjx5spgGIG3btq1NfS1evFjS6XRium/fvtKzzz5727HXrl2TXFxcpJSUlFbX179/f1H3DQsWLJAiIyPFdGRkpDRgwACpubn5jrVVVFRIAKTDhw9LkiRJmzdvlpydnaWysrLbjr98+bLk6OgoffXVV2JeRESEtHjx4jtuhzovjW0jiR50Dz30kMW0r68vfH19W8y78Vf+6dOnAQBjx461GDN27Fh8/fXXYkxwcDA8PDzE8mHDhqF79+5i+tixY2hsbETv3r0t1tPY2IgBAwbIrt9sNmPNmjXYsWMHLly4AKPRiKamJvTv3x/Az7tmysrKMGHChNs+vrCwEEajsdXlbREWFgYHB8sP/wUFBXjllVdQUFAAg8Eg/uL/8ccfMXr0aBw/fhxDhgxBnz59brtOHx8fTJ48GZs2bYJOp8OpU6eQm5uLTZs23Xe91DExFMimHB0dLaZVKtVt55nN5nbdrtlsRvfu3XHs2LEWy5ycnGSvZ+3atXjzzTfx7rvvIiQkBO7u7nj33Xexc+fOdqvVwcGhxTGKpqamFuO6dOliMV1fX48JEybgkUceQWZmJnx8fAAAQ4cObdOB6GeeeQaTJk2CwWDA5s2bMXLkSAwbNuweOqHOgMcUqFMZOnQoACAnJ8difk5OjvhFNWTIEBQVFaG6ulosLywsxE8//SSmw8PDUV1dDaPRiKCgIIt/Nw7SypGTk4Po6GjMnz8fISEhCAoKQklJiVju7e2NPn36tDgQfsOQIUPg4uLS6vIb67h48aLFvBMnTty1tqKiIly9ehVvvPEGxo0bh+DgYFRVVVkETFhYGE6fPo0LFy60up7x48ejX79+2LhxI7Zt24annnrqrtumzouhQJ1KYGAg4uLiEB8fjz179uDMmTNYsmQJTp06hcTERADAzJkz4e7ujlmzZuHkyZPIzc3F/Pnz4erqKtYzfvx46HQ6TJ06FZ999hlKS0tx/PhxpKamtmnXyKBBg3Dw4EEcOHAAxcXFWLlyJb755huLMUlJSdi4cSNee+01FBUVobCwEBs2bIDBYEDXrl3xpz/9CS+//DLS0tJQXFyMkydP4s033xSP1+l0yMrKwt69e3H27Fk8//zz+PHHH+9aW//+/eHs7IzU1FR8//332LdvH5YsWQKVSiXGzJgxA/3798djjz0GvV6P8+fPY9++fcjKyhJjVCoVFi5ciFdffRXNzc2YPn267OeHOiEbH9OgB1hkZKS0YMECi3lRUVHSnDlzLOZNnDhR+uMf/yimf/rpJ2nhwoWSVquVnJycpLCwMGnPnj0Wj8nPz5ciIiIkJycnKSAgQPr4449bHLCtr6+Xli5dKvn7+0uOjo6Sj4+PNHHiRGnfvn1iDO5yoLm6ulqKi4uT3N3dJU9PTyk+Pl5auXKl1L9/f4tx27dvl4YPHy45OTlJnp6e0qRJk6SqqipJkiTJbDZL69atkwYOHCg5OjpK3t7e0rRp08Rja2pqpFmzZkk9evSQevbsKSUlJd32QPOtz6UkSdInn3wiBQUFSc7OztLDDz8sHTx4UFKr1VJmZqYYc+nSJWn27NmSl5eX5OzsLA0aNMhiuSRJ0tWrVyVHR0cpPj6+1eeC7INKknjnNSK6s8LCQgwbNgwFBQUtTg4g+8JQIKJWNTQ0wGAwYNGiRbh27Rr2799v65LIynhMgYha9fHHH6Nv3744f/48/vKXv9i6HFIAPykQEZHATwpERCQwFIiISOj032i+9Us97UWr1cJgMFhl3bZgb/0A9tcT++n47KUnPz+/VpfxkwIREQkMBSIiEhgKREQkdPpjCreSJAlGoxFms9niGi9tdeXKFTQ0NLRjZbYlpx9JkuDg4AAXF5f7eu6IqPOyu1AwGo1wdHSERnN/rWk0GqjV6naqyvbk9mMymWA0Gi0uHkdEDw67231kNpvvOxAeZBqNpt3vXUBEnYcivz0bGxuRlJQEk8mE5uZmRERE4PHHH7cY09TUhA0bNqC0tBTu7u5ISEiAt7d3m7fF3R73j88h0YNLkU8Kjo6OSEpKQkpKCtasWYOCggIUFxdbjNm/fz+6dOmC1NRUxMTE4MMPP1SiNCIiuokinxRUKhVcXFwAAM3NzWhubm7x12heXh7i4uIAABEREcjIyIAkSff9V2vzU4/d2+Nama/e9Pm9F0NE1MEptvPdbDZj6dKluHz5MiZOnNji5uiVlZXw8vICAKjVari5uaG2thbdunWzGKfX66HX6wEAycnJ0Gq1FsuvXLlicUyhtV/u96ojHa8wmUxtqkfuWGdn5xbPa0ek0Wg6RZ1ydfZ+rvzXKMtpBbft84+jimyns79Gcij2G87BwQEpKSmoq6vD22+/jX//+99tuhfuDTqdDjqdTkzf+pXzhoYGq541ZDKZZI2bP38+Ll68iIaGBixYsACzZs3CgQMHkJycjObmZnh6eiI7Oxt1dXVYuXIlvv32W6hUKjz//POIiYnBgAEDxL1+/+///g96vR7r1q1DQkICnJ2dUVhYiPDwcEyePBkvvfQSGhoa4OLignfeeQdBQUFobm7GG2+8gYMHD8LBwQGzZs1CUFAQMjIykJGRAeDn+wv/9a9/RXp6ukXtN66h39HZyyUHbrC3fpSk1PNmL6/RnS5zofifvV26dMHQoUNRUFBgEQqenp6oqKiAl5cXmpubUV9fD3d3d6XLazdr166Fh4cHrl+/jpiYGEycOBGJiYn4+9//jn79+qGqqgoAsG7dOri7u2Pfvn0AYHGz+dZcunQJ//znP6FWq1FbW4t//OMf0Gg0yMnJwVtvvYVNmzZh+/btKCsrw969e6HRaFBbW4uuXbti+fLl4nnOysri/XaJyIIioVBTUwO1Wo0uXbqgsbER3377LSZPnmwxJiwsDAcPHsTAgQORm5uLoUOHduqzYDIyMrBr1y4AP1+0b/v27YiIiBBB6OHhAQA4dOgQ3n//ffG4Hj163HXdsbGx4tNQTU0NEhIScP78eahUKjQ1NQEADh8+jNmzZ4tdRh4eHjCZTPjDH/6ATz/9FNOnT8fx48fx3nvvtV/TRNTpKRIKVVVVSEtLg9lshiRJGDlyJMLCwpCVlYXAwECEh4dj/Pjx2LBhA/7nf/4HXbt2RUJCghKlWcXRo0dx6NAhfPHFF3B1dcW0adMwdOhQfP/997LXcXMg3vpNZDc3N/FzSkoKRo0ahfT0dJSVlWHatGl3XO/06dMxd+5cODs7IzY2tkMdIyEi21PkN0L//v2xZs2aFvNv3nXh5OSEF154QYlyrK62thbdu3eHq6srzp07h/z8fDQ0NCA3N1ccS6mqqoKHhwfGjh2LLVu24NVXXwXw8+6jHj16oGfPnigpKUFgYCB2796NLl26tLotX19fAEB2draYP2bMGGzbtg2jRo2CRqNBVVUV3N3d4evrCx8fH6xfvx47duyw/pNBRJ2K3f+ZeK+nkGo0GtkHlW81btw4bNu2DZGRkQgMDERoaCi8vLywZs0aPPnkkzCbzdBqtdixYweWLFmC5cuXY/z48XBwcMALL7yASZMm4cUXX8ScOXPg6emJhx56CHV1dbfd1qJFi5CQkID33nsPUVFRYv7MmTNRWloKnU4HjUaD2bNnY86cOQCAqVOnoqKiosUZYEREnf4ezbfeZKe+vt5i98q9up9Q6Ihu7mfFihUYNmwYZsyYcdux7fUcWpu9nAlyQ2fv516/E9QelPr+UGd/jW7gTXZIiI6ORlFREaZOnWrrUoioA7L73Udkaffu3bYugYg6MLv7pNDJ94Z1CHwOiR5cdhcKDg4OdnUsQGkmkwkODnb3tiAimexu95GLiwuMRiMaGhru68tvzs7OdnXnNTn93HznNSJ6MNldKKhUqna5a5i9nGVwg731Q0TWwf0EREQkMBSIiEhgKBARkcBQICIigaFAREQCQ4GIiASGAhERCQwFIiISGApERCQwFIiISGAoEBGRwFAgIiKBoUBERAJDgYiIBIYCEREJDAUiIhIYCkREJChy5zWDwYC0tDRUV1dDpVJBp9Nh0qRJFmMKCwuxZs0aeHt7AwBGjBiBadOmKVEeERH9QpFQUKvVmD17NgICAnD9+nUsW7YMw4cPR58+fSzGBQcHY9myZUqUREREt6HI7iMPDw8EBAQAAFxdXdG7d29UVlYqsWkiImoDRT4p3Ky8vBznz59HUFBQi2XFxcVITEyEh4cHZs+ejb59+7YYo9frodfrAQDJycnQarVWqVOj0Vht3bZgb/0A9tdTZ+/nig23rdTz1tlfIzlUkiRJSm3MaDQiKSkJU6dOxYgRIyyW1dfXw8HBAS4uLsjPz8eWLVuwfv36u67z4sWLVqlVq9XCYDBYZd22YG/9APbXU2fvp/mpx2y2bfWmzxXZTmd/jW7w8/NrdZliZx+ZTCasXbsWY8aMaREIAODm5gYXFxcAQGhoKJqbm1FTU6NUeUREBIVCQZIkfPDBB+jduzdiY2NvO6a6uho3PrScO3cOZrMZ7u7uSpRHRES/UOSYwtmzZ5GTk4N+/fohMTERADBjxgzxMWzChAnIzc3F3r17oVar4eTkhISEBKhUKiXKIyKiXygSCoMHD0Z2dvYdx0RHRyM6OlqJcoiIqBX8RjMREQkMBSIiEhgKREQkMBSIiEhgKBARkcBQICIigaFAREQCQ4GIiASGAhERCQwFIiISGApERCQwFIiISGAoEBGRwFAgIiKBoUBERAJDgYiIBIYCEREJDAUiIhIYCkREJDAUiIhIYCgQEZHAUCAiIoGhQEREAkOBiIgEhgIREQkMBSIiEjRKbMRgMCAtLQ3V1dVQqVTQ6XSYNGmSxRhJkpCZmYkTJ07A2dkZ8fHxCAgIUKI8IiL6hSKhoFarMXv2bAQEBOD69etYtmwZhg8fjj59+ogxJ06cwOXLl7F+/XqUlJRg8+bNWL16tRLlERHRLxTZfeTh4SH+6nd1dUXv3r1RWVlpMSYvLw9jx46FSqXCwIEDUVdXh6qqKiXKIyKiXyjySeFm5eXlOH/+PIKCgizmV1ZWQqvVimkvLy9UVlbCw8PDYpxer4derwcAJCcnWzymPWk0Gqut2xbsrR/A/npqr36u/Neodqimc1HqfWBv77nbUTQUjEYj1q5di7lz58LNze2e1qHT6aDT6cS0wWBor/IsaLVaq63bFuytH8D+erK3fpSk1PNmL6+Rn59fq8sUO/vIZDJh7dq1GDNmDEaMGNFiuaenp8WTXVFRAU9PT6XKIyIiKBQKkiThgw8+QO/evREbG3vbMeHh4cjJyYEkSSguLoabm1uLXUdERGRdiuw+Onv2LHJyctCvXz8kJiYCAGbMmCE+GUyYMAEhISHIz8/H4sWL4eTkhPj4eCVKIyKim8gOhZSUFERGRiI0NBQaTduyZPDgwcjOzr7jGJVKhSeffLJN6yUiovYle/dRcHAwPv30UyxcuBCbNm3C2bNnrVkXERHZgOw/+WNjYxEbG4uysjIcOnQI7733HjQaDcaOHYtHHnkEvr6+1qyTiIgU0OZjCn379sXMmTMREhKCjIwMfPLJJ/jiiy8QFBSE2bNnw9/f3wplEhGREtoUChcvXkROTg6OHDkCjUaDMWPGYOnSpejWrRv27t2LlJQUpKWlWatWIiKyMtmhsGzZMly9ehUjR47E4sWLMWDAAIvlsbGx2LVrV7sXSEREypEdClOmTEF4ePgdzzzipwQios5N9tlHrq6uKC8vt5h38eJFfPvtt+1eFBER2YbsUEhPT4erq6vFPBcXF6Snp7d7UUREZBuyQ+Gnn35qcdkJDw8PVFdXt3tRRERkG7JDwcfHB6dOnbKYV1hYCG9v73YvioiIbEP2gea4uDi8/fbbGD9+PHx8fHDlyhUcOHCA1ygiIrIjsj8p/PrXv8bKlSthNBqRn58Po9GIFStW4Ne//rU16yMiIgW16ctrQUFBLe6YRkRE9qNNofDDDz+gqKgItbW1kCRJzJ8+fXq7F0ZERMqTHQp6vR5//etfMXz4cBQUFODhhx/Gt99+i/DwcGvWR0RECpJ9TOGf//wnli9fjsTERDg5OSExMREvvPAC1Gq1NesjIiIFyQ6FmpoaBAcHA/j5hjhmsxkhISE4fvy41YojIiJlyd595OnpifLycnh7e6NXr17Iy8uDu7t7m+/CRkREHZfs3+iTJ0/Gf/7zH3h7e2PatGl45513YDKZMG/ePGvWR0RECpIVCpIkITg4GFqtFgAQEhKCzMxMmEwmuLi4WLVAIiJSjqxjCiqVCn/+85+hUqnEPI1Gw0AgIrIzsg80+/v749KlS9ashYiIbEz2MYWhQ4di9erViIyMFLuRbhg/fny7F0ZERMqTHQpnz56Ft7c3ioqKWixjKBAR2QfZoZCUlGTNOoiIqAOQHQpms7nVZQ4Odz408f777yM/Px/du3fH2rVrWywvLCzEmjVrxL0ZRowYgWnTpsktjYiI2onsUJgxY0ary7Kysu742HHjxiE6OhppaWmtjgkODsayZcvklkNERFYgOxQ2bNhgMV1VVYXPPvtM1gXxhgwZgvLy8rZXR0REipIdCj179mwx/dxzz+HFF19slwPNxcXFSExMhIeHB2bPno2+ffvedpxer4derwcAJCcntzgTqr1oNBqrrdsW7K0fwP56aq9+rrRDLZ2NUu8De3vP3c59Xbiovr4eNTU1913Er371K7z//vtwcXFBfn4+UlJSsH79+tuO1el00Ol0YtpgMNz39m9Hq9Vabd22YG/9APbXk731oySlnjd7eY38/PxaXSY7FFJTUy2+0dzQ0ICioiKMGTPm/qoD4ObmJn4ODQ1Feno6ampq0K1bt/teNxERySc7FHx9fS2mnZ2d8dvf/hbDhw+/7yKqq6vRvXt3qFQqnDt3DmazGe7u7ve9XiIiahvZoRAXF3fPG1m3bh1Onz6N2tpaPPPMM3j88cdhMpkAABMmTEBubi727t0LtVoNJycnJCQkWHwqISIiZcgOhYyMDIwePRqDBg0S886ePYuvv/4ac+fOveNjExIS7rg8Ojoa0dHRckshIiIrkX1BvCNHjiAwMNBiXkBAAA4fPtzuRRERkW3IDoUbt+C8mdlshiRJ7V4UERHZhuxQGDx4MHbs2CGCwWw245NPPsHgwYOtVhwRESlL9jGFefPmITk5GU8//bQ4V9fDwwNLly61Zn1ERKQg2aHg5eWFt956C+fOnUNFRQW8vLwQFBR014vhERFR5yE7FH744Qd07doVAwcOFPMMBgOuXbsGf39/a9RGREQKk/1nfmpqKpqbmy3mmUymFhfKIyKizkt2KBgMBvj4+FjM8/X1xdWrV9u9KCIisg3ZoeDp6YnS0lKLeaWlpfDw8Gj3ooiIyDZkH1OIiYlBSkoKHnvsMfj4+ODKlSv44osvMHXqVGvWR0RECpIdCjqdDl26dMH+/ftRUVEBrVaLJ554AhEREdasj4iIFNSm+ykEBwfD0dFR3EOhvr4e+/fvb5eb7BARke3JDoV//etf2LBhA3x9fVFWVoa+ffuirKwMgwcPZigQEdkJ2aGQlZWFRYsWYeTIkZg3bx7WrFmDAwcOoKyszJr1ERGRgtp0SurIkSMt5kVGRiInJ6fdiyIiItuQHQrdunVDdXU1AKBnz54oLi7GlStXWlw5lYiIOi/Zu4+ioqJw5swZREREICYmBq+88gpUKhViY2OtWR8RESlIdihMmTJF/BwZGYmhQ4fCaDSiT58+VimMiIiU16ZTUm+m1Wrbsw4iIuoAeN1rIiISGApERCQwFIiISGAoEBGRwFAgIiKBoUBERAJDgYiIhHv+nkJbvP/++8jPz0f37t2xdu3aFsslSUJmZiZOnDgBZ2dnxMfHIyAgQInSiIjoJop8Uhg3bhyWL1/e6vITJ07g8uXLWL9+PRYuXIjNmzcrURYREd1CkVAYMmQIunbt2uryvLw8jB07FiqVCgMHDkRdXR2qqqqUKI2IiG6iyO6ju6msrLS4bIaXlxcqKyvh4eHRYqxer4derwcAJCcn3/PlNq7816g7L7+ntcrj84+jVlz77Wk0GjQ/9Zji273BGj1rNJq7vv53e52tqa09y+lHDmu+dzsqpd7bHem5tdbvkQ4RCm2h0+mg0+nEtMFgsGE198YWNdv6WlXW6Fmr1Xbo17+ttXX0fqhjuZ/3ip+fX6vLOsTZR56enhYNVlRUwNPT04YVERE9mDpEKISHhyMnJweSJKG4uBhubm633XVERETWpcjuo3Xr1uH06dOora3FM888g8cffxwmkwkAMGHCBISEhCA/Px+LFy+Gk5MT4uPjlSiLiIhuoUgoJCQk3HG5SqXCk08+qUQpRER0Bx1i9xEREXUMDAUiIhIYCkREJDAUiIhIYCgQEZHAUCAiIoGhQEREAkOBiIgEhgIREQkMBSIiEhgKREQkMBSIiEhgKBARkcBQICIigaFAREQCQ4GIiASGAhERCQwFIiISGApERCQwFIiISGAoEBGRwFAgIiKBoUBERAJDgYiIBIYCEREJGqU2VFBQgMzMTJjNZkRFRWHKlCkWyw8ePIht27bB09MTABAdHY2oqCilyiMiIigUCmazGenp6Vi5ciW8vLzw4osvIjw8HH369LEYN2rUKCxYsECJkoiI6DYU2X107tw5+Pr6wsfHBxqNBqNGjcKxY8eU2DQREbWBIp8UKisr4eXlJaa9vLxQUlLSYtw333yDoqIi9OrVC3PmzIFWq20xRq/XQ6/XAwCSk5NvO0aOK/f0qPZxrzXfD41GsT2Ft2WNnjUazV3X25leZzn9yGHLnkk51vo9YtvfFDcJCwvD6NGj4ejoiK+++gppaWlISkpqMU6n00Gn04lpg8GgZJntwhY12yKIbmaNnrVabYd+/dtaW0fvhzqW+3mv+Pn5tbpMkd1Hnp6eqKioENMVFRXigPIN7u7ucHR0BABERUWhtLRUidKIiOgmioRCYGAgLl26hPLycphMJhw9ehTh4eEWY6qqqsTPeXl5LQ5CExGR9Smy+0itVmP+/Pl44403YDab8eijj6Jv377IyspCYGAgwsPDsWvXLuTl5UGtVqNr166Ij49XojQiIrqJYscUQkNDERoaajFv+vTp4ueZM2di5syZSpVDRES3wW80ExGRwFAgIiKBoUBERAJDgYiIBIYCEREJDAUiIhIYCkREJDAUiIhIYCgQEZHAUCAiIoGhQEREAkOBiIgEhgIREQkMBSIiEhgKREQkMBSIiEhgKBARkcBQICIigaFAREQCQ4GIiASGAhERCQwFIiISGApERCQwFIiISGAoEBGRwFAgIiJBo9SGCgoKkJmZCbPZjKioKEyZMsVieVNTEzZs2IDS0lK4u7sjISEB3t7eSpVHRERQ6JOC2WxGeno6li9fjnfffRdHjhzBhQsXLMbs378fXbp0QWpqKmJiYvDhhx8qURoREd1EkVA4d+4cfH194ePjA41Gg1GjRuHYsWMWY/Ly8jBu3DgAQEREBE6dOgVJkpQoj4iIfqHI7qPKykp4eXmJaS8vL5SUlLQ6Rq1Ww83NDbW1tejWrZvFOL1eD71eDwBITk6Gn5/fvRW1M+/eHteJ9bXDnu/6+neynu/5/XyzTtYzdSyd7kCzTqdDcnIykpOTrbqdZcuWWXX9SrO3fgD764n9dHz22NOtFAkFT09PVFRUiOmKigp4enq2Oqa5uRn19fVwd3dXojwiIvqFIqEQGBiIS5cuoby8HCaTCUePHkV4eLjFmLCwMBw8eBAAkJubi6FDh0KlUilRHmz4ND4AAAf0SURBVBER/UL98ssvv2ztjTg4OMDX1xepqanYvXs3xowZg4iICGRlZcFoNMLPzw/9+vXD4cOH8dFHH+GHH37AwoUL0bVrV2uXdkcBAQE23X57s7d+APvrif10fPbY081UEk/xISKiX3S6A81ERGQ9DAUiIhIUu8xFR3W3y2/s3bsXe/bsgYODA1xcXPD000+jT58+Nqr27u7Wzw25ubl455138OabbyIwMFDhKuW7Wz8HDx7Etm3bxNls0dHRiIqKskWpssl5jY4ePYpPPvkEKpUK/fv3x5IlS2xQqTx362fLli0oLCwEADQ2NuKnn37Cli1bbFCpfHfryWAwIC0tDXV1dTCbzZg5cyZCQ0NtVG07kx5gzc3N0nPPPSddvnxZampqkv785z9LZWVlFmPq6urEz8eOHZNef/11pcuUTU4/kiRJ9fX10ksvvSQtX75cOnfunA0qlUdOPwcOHJA2b95sowrbTk5PFy9elBITE6Xa2lpJkiSpurraFqXKIvc9d8OXX34ppaWlKVhh28np6YMPPpD27NkjSZIklZWVSfHx8bYo1Soe6N1Hci6/4ebmJn42Go0d+jRZOf0AQFZWFiZPngxHR0cbVCmf3H46Ezk97du3DxMnThRn33Xv3t0WpcrS1tfoyJEjeOSRRxSssO3k9KRSqVBfXw8AqK+vh4eHhy1KtYoHeveRnMtvAMDu3buxc+dOmEwmvPTSS0qW2CZy+iktLYXBYEBoaCg+//xzpUtsE7mvzzfffIOioiL06tULc+bMgVarVbLMNpHT08WLFwEAq1atgtlsRlxcHB5++GFF65RL7msEAFevXkV5eTmGDRumVHn3RE5PcXFxeP3117F79240NDRg1apVSpdpNQ/0JwW5oqOjkZqaij/+8Y/49NNPbV3OPTObzdi6dSueeOIJW5fSbsLCwpCWloa3334bw4cPR1pamq1Lum9msxmXLl1CUlISlixZgo0bN6Kurs7WZd23I0eOICIiAg4Onf/XzpEjRzBu3Dh88MEHePHFF5Gamgqz2WzrstpF53917oOcy2/crKPvvrhbP0ajEWVlZXjllVfw7LPPoqSkBGvWrMH3339vi3LvSs7r4+7uLnaDRUVFobS0VNEa20ruJV/Cw8Oh0Wjg7e2NXr164dKlS0qXKktb/g8dPXoUo0ePVqq0eyanp/3792PkyJEAgIEDB6KpqQm1tbWK1mktD3QoyLn8xs3/GfPz89GrVy+ly5Ttbv24ubkhPT0daWlpSEtLw4ABA/C///u/HfbsIzmvT1VVlfg5Ly+vQ58ZBsjr6Te/+Y04W6empgaXLl2Cj4+PLcq9Kzn9AMB//vMf1NXVYeDAgTaosm3k9KTVanHq1CkAwIULF9DU1NTiis6d1QN9TEGtVmP+/Pl44403YDab8eijj6Jv377IyspCYGAgwsPDsXv3bnz33XdQq9Xo2rUrnn32WVuX3So5/XQmcvrZtWsX8vLyxOsTHx9v67LvSE5PDz30EE6ePInnn38eDg4OmDVrVoe9OKTc99yRI0cwatSoDn2ixg1yenriiSewceNG7Ny5EwAQHx/fKXqTg5e5ICIi4YHefURERJYYCkREJDAUiIhIYCgQEZHAUCAiIoGhQGRj5eXlePzxx9Hc3GzrUogYCkRE9P8xFIiISHigv9FM1JrKykpkZGSgqKgILi4uiImJwaRJk5CdnY2ysjI4ODjgxIkT6NWrFxYtWgR/f38AP1/yYPPmzfjhhx/g6emJmTNnim/1NjY2YseOHcjNzUVdXR369etncXXNQ4cOISsrC42NjYiJicHUqVNt0To94PhJgegWZrMZb731Fvz9/bFx40a89NJL+PLLL1FQUADg52ssjRw5EhkZGRg9ejRSUlJgMplgMpnw1ltvYfjw4di8eTPmz5+P9evXi0thb926FaWlpXj99deRmZmJWbNmWVwa4cyZM3jvvfewatUq/O1vf8OFCxds0j892BgKRLf4/vvvUVNTg2nTpkGj0cDHxwdRUVE4evQoACAgIAARERHQaDSIjY1FU1MTSkpKUFJSAqPRiClTpkCj0WDYsGEIDQ3F4cOHYTabceDAAcydOxeenp5wcHDAoEGDLG50FBcXBycnJ/j7+6N///748ccfbfUU0AOMu4+IbnH16lVUVVVh7ty5Yp7ZbEZwcDC0Wq3FDVgcHBzg5eUlrtaq1Wot7hfQs2dPVFZWora2Fk1NTfD19W11uz169BA/Ozs7w2g0tmNXRPIwFIhuodVq4e3tjfXr17dYlp2dbXGtfbPZjIqKCnE7RoPBALPZLILBYDCgV69e4r4Ply9fFscfiDoi7j4iukVQUBBcXV3x2WefobGxEWazGf/+979x7tw5AD/f0vSbb75Bc3MzvvzySzg6OmLAgAEYMGAAnJ2d8fnnn8NkMqGwsBDHjx/H6NGj4eDggEcffRRbt25FZWUlzGYziouL0dTUZONuiSzx0tlEt1FZWYmtW7eisLAQJpMJfn5+mD59Os6cOWNx9pGvry+eeeYZBAQEAADKysoszj6aMWMGfvOb3wD4+eyjjz76CF9//TWMRiP8/f2xYsUKVFdX47nnnsPHH38MtVoNAHj55ZcxZswYREVF2ew5oAcTQ4GoDbKzs3H58mUsXrzY1qUQWQV3HxERkcBQICIigbuPiIhI4CcFIiISGApERCQwFIiISGAoEBGRwFAgIiLh/wH62rCby8jzLwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Media conjunto de teste 1.8175783514976502\n",
            "Media conjunto de treinamento 1.8175783514976502\n",
            "desvio padrao conjunto de teste 0.16247867229529356\n",
            "desvio padrao conjunto de treinamento: 0.16247867229529356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYAxXbC8zSmb"
      },
      "source": [
        "from keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class_names = ['a', 'b', 'c', ...] # fill the rest\n",
        "\n",
        "model = load_model('model.h5')\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "img = cv2.imread('test.jpg')\n",
        "img = cv2.resize(img,(320,240))\n",
        "img = np.reshape(img,[1,320,240,3])\n",
        "\n",
        "classes = np.argmax(model.predict(img), axis = -1)\n",
        "\n",
        "print(classes)\n",
        "\n",
        "names = [class_names[i] for i in classes]\n",
        "\n",
        "print(names)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}